{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost cudf-cu12 cuml-cu12 --extra-index-url=https://pypi.nvidia.com --quiet\n"
      ],
      "metadata": {
        "id": "oZIgfiyH-NGp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# üß† GPU-Accelerated Phishing URL Detection (Balanced Version)\n",
        "#  ‚úÖ XGBoost (GPU) + cuML RandomForest (GPU)\n",
        "#  ‚úÖ SMOTE Oversampling + Threshold Tuning\n",
        "#  ‚úÖ False Positive Correction for Trusted Domains\n",
        "#  ‚úÖ Model Saving (.pkl via joblib)\n",
        "# ==========================================================\n",
        "\n",
        "!pip install xgboost cudf-cu12 cuml-cu12 imbalanced-learn joblib --extra-index-url=https://pypi.nvidia.com --quiet\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from urllib.parse import urlparse\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "from cuml.ensemble import RandomForestClassifier as cuRF\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "class URLSafetyGPU:\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "    def calculate_entropy(self, string):\n",
        "        if not string:\n",
        "            return 0\n",
        "        prob = [float(string.count(c)) / len(string) for c in set(string)]\n",
        "        return -sum(p * np.log2(p) for p in prob if p > 0)\n",
        "\n",
        "    def extract_url_features(self, urls):\n",
        "        feats = []\n",
        "        for url in urls:\n",
        "            p = urlparse(url)\n",
        "            feats.append({\n",
        "                \"length\": len(url),\n",
        "                \"num_dots\": url.count('.'),\n",
        "                \"num_hyphens\": url.count('-'),\n",
        "                \"num_digits\": sum(c.isdigit() for c in url),\n",
        "                \"num_slashes\": url.count('/'),\n",
        "                \"entropy\": self.calculate_entropy(url),\n",
        "                \"has_ip\": int(bool(re.search(r'\\d+\\.\\d+\\.\\d+\\.\\d+', url))),\n",
        "                \"suspicious_tld\": int(any(t in url.lower() for t in ['.tk','.ml','.ga','.cf','.cc','.pw'])),\n",
        "                \"phish_keywords\": sum(k in url.lower() for k in\n",
        "                                      ['secure','account','update','bank','paypal','login','verify']),\n",
        "                \"domain_len\": len(p.netloc),\n",
        "                \"path_len\": len(p.path),\n",
        "            })\n",
        "        return pd.DataFrame(feats)\n",
        "\n",
        "    def prepare_data(self, df, url_col='url', label_col='type'):\n",
        "        X = self.extract_url_features(df[url_col])\n",
        "        y = df[label_col].apply(\n",
        "            lambda x: 'safe' if str(x).lower() in ['benign','benigndefacement'] else 'not_safe'\n",
        "        )\n",
        "        y_encoded = self.label_encoder.fit_transform(y)\n",
        "        return X, y_encoded, y\n",
        "\n",
        "    def train_xgboost_gpu(self, X, y_encoded):\n",
        "        X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "            X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        "        )\n",
        "\n",
        "        # üß© Balance with SMOTE\n",
        "        print(\"\\n‚öñÔ∏è Applying SMOTE Oversampling...\")\n",
        "        smote = SMOTE(random_state=42)\n",
        "        X_tr_bal, y_tr_bal = smote.fit_resample(X_tr, y_tr)\n",
        "        print(f\"After SMOTE: {np.bincount(y_tr_bal)} (balanced)\")\n",
        "\n",
        "        print(\"\\n‚ö° Training XGBoost (GPU)...\")\n",
        "        self.model = XGBClassifier(\n",
        "            n_estimators=250,\n",
        "            learning_rate=0.1,\n",
        "            max_depth=6,\n",
        "            tree_method='gpu_hist',\n",
        "            predictor='gpu_predictor',\n",
        "            random_state=42,\n",
        "            eval_metric='logloss'\n",
        "        )\n",
        "        self.model.fit(X_tr_bal, y_tr_bal)\n",
        "\n",
        "        probs = self.model.predict_proba(X_te)[:, 1]\n",
        "        preds = (probs > 0.4).astype(int)\n",
        "\n",
        "        acc = accuracy_score(y_te, preds)\n",
        "        print(f\"‚úÖ XGBoost (GPU) Accuracy: {acc:.4f}\")\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(classification_report(y_te, preds, target_names=['safe','not_safe']))\n",
        "        print(\"Confusion Matrix:\\n\", confusion_matrix(y_te, preds))\n",
        "\n",
        "        # üíæ Save the trained model and encoder\n",
        "        joblib.dump(self.model, \"xgboost_gpu_model.pkl\")\n",
        "        joblib.dump(self.label_encoder, \"label_encoder.pkl\")\n",
        "        print(\"üì¶ Saved: xgboost_gpu_model.pkl & label_encoder.pkl\")\n",
        "\n",
        "    def train_random_forest_gpu(self, X, y_encoded):\n",
        "        X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "            X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        "        )\n",
        "        smote = SMOTE(random_state=42)\n",
        "        X_tr_bal, y_tr_bal = smote.fit_resample(X_tr, y_tr)\n",
        "\n",
        "        print(\"\\n‚ö° Training cuML Random Forest (GPU)...\")\n",
        "        self.model = cuRF(\n",
        "            n_estimators=200,\n",
        "            max_depth=12,\n",
        "            bootstrap=True,\n",
        "            random_state=42,\n",
        "            n_streams=4\n",
        "        )\n",
        "        self.model.fit(X_tr_bal, y_tr_bal)\n",
        "\n",
        "        preds = self.model.predict(X_te)\n",
        "        acc = accuracy_score(y_te, preds)\n",
        "        print(f\"‚úÖ Random Forest (GPU) Accuracy: {acc:.4f}\")\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(classification_report(y_te, preds, target_names=['safe','not_safe']))\n",
        "        print(\"Confusion Matrix:\\n\", confusion_matrix(y_te, preds))\n",
        "\n",
        "        # üíæ Save Random Forest model\n",
        "        joblib.dump(self.model, \"random_forest_gpu_model.pkl\")\n",
        "        print(\"üì¶ Saved: random_forest_gpu_model.pkl\")\n",
        "\n",
        "    # ------------------ URL Prediction (with False Positive Check) ------------------\n",
        "    def predict_url(self, url):\n",
        "        feats = self.extract_url_features([url])\n",
        "        pred = None\n",
        "\n",
        "        if hasattr(self.model, \"predict_proba\"):\n",
        "            try:\n",
        "                prob = self.model.predict_proba(feats)[0][1]\n",
        "                pred = 1 if prob > 0.4 else 0\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        if pred is None:\n",
        "            pred = int(self.model.predict(feats)[0])\n",
        "\n",
        "        label = self.label_encoder.inverse_transform([pred])[0]\n",
        "\n",
        "        # ‚úÖ False Positive Correction\n",
        "        safe_domains = [\n",
        "            'google.com', 'youtube.com', 'microsoft.com', 'apple.com',\n",
        "            'amazon.com', 'wikipedia.org', 'facebook.com', 'instagram.com',\n",
        "            'linkedin.com', 'yahoo.com'\n",
        "        ]\n",
        "\n",
        "        for domain in safe_domains:\n",
        "            if domain in url.lower() and label == 'not_safe':\n",
        "                print(f\"‚ö†Ô∏è False Positive Detected: {url}\")\n",
        "                print(f\"‚úÖ Corrected ‚Üí Safe (Trusted Domain Match: {domain})\")\n",
        "                label = 'safe'\n",
        "                break\n",
        "\n",
        "        return label\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"üìÇ Loading dataset ...\")\n",
        "    df = pd.read_csv('/content/drive/MyDrive/malicious_phish.csv')\n",
        "    print(f\"‚úÖ Loaded {len(df)} samples\")\n",
        "\n",
        "    clf = URLSafetyGPU()\n",
        "    print(\"\\nüîß Extracting features ...\")\n",
        "    X, y_encoded, y_original = clf.prepare_data(df)\n",
        "    print(f\"Feature shape: {X.shape}\")\n",
        "    print(pd.Series(y_original).value_counts())\n",
        "\n",
        "    # Train and Save Models\n",
        "    clf.train_xgboost_gpu(X, y_encoded)\n",
        "    clf.train_random_forest_gpu(X, y_encoded)\n",
        "\n",
        "    print(\"\\n================= TESTING URLs =================\")\n",
        "    test_urls = [\n",
        "        'https://www.google.com',\n",
        "        'http://paypal-update.tk/verify-account',\n",
        "        'http://192.168.1.1/login'\n",
        "    ]\n",
        "    for u in test_urls:\n",
        "        pred = clf.predict_url(u)\n",
        "        print(f\"üîç {u} ‚Üí {pred}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1E6SxtEi-cE4",
        "outputId": "e95c02ef-15cb-40e5-9df0-4849b328ff50"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Loading dataset ...\n",
            "‚úÖ Loaded 651192 samples\n",
            "\n",
            "üîß Extracting features ...\n",
            "Feature shape: (651192, 11)\n",
            "type\n",
            "safe        428104\n",
            "not_safe    223088\n",
            "Name: count, dtype: int64\n",
            "\n",
            "‚öñÔ∏è Applying SMOTE Oversampling...\n",
            "After SMOTE: [342483 342483] (balanced)\n",
            "\n",
            "‚ö° Training XGBoost (GPU)...\n",
            "‚úÖ XGBoost (GPU) Accuracy: 0.9436\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        safe       0.93      0.91      0.92     44618\n",
            "    not_safe       0.95      0.96      0.96     85621\n",
            "\n",
            "    accuracy                           0.94    130239\n",
            "   macro avg       0.94      0.94      0.94    130239\n",
            "weighted avg       0.94      0.94      0.94    130239\n",
            "\n",
            "Confusion Matrix:\n",
            " [[40492  4126]\n",
            " [ 3213 82408]]\n",
            "üì¶ Saved: xgboost_gpu_model.pkl & label_encoder.pkl\n",
            "\n",
            "‚ö° Training cuML Random Forest (GPU)...\n",
            "‚úÖ Random Forest (GPU) Accuracy: 0.9381\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        safe       0.90      0.92      0.91     44618\n",
            "    not_safe       0.96      0.95      0.95     85621\n",
            "\n",
            "    accuracy                           0.94    130239\n",
            "   macro avg       0.93      0.93      0.93    130239\n",
            "weighted avg       0.94      0.94      0.94    130239\n",
            "\n",
            "Confusion Matrix:\n",
            " [[41023  3595]\n",
            " [ 4467 81154]]\n",
            "üì¶ Saved: random_forest_gpu_model.pkl\n",
            "\n",
            "================= TESTING URLs =================\n",
            "‚ö†Ô∏è False Positive Detected: https://www.google.com\n",
            "‚úÖ Corrected ‚Üí Safe (Trusted Domain Match: google.com)\n",
            "üîç https://www.google.com ‚Üí safe\n",
            "üîç http://paypal-update.tk/verify-account ‚Üí not_safe\n",
            "üîç http://192.168.1.1/login ‚Üí not_safe\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}